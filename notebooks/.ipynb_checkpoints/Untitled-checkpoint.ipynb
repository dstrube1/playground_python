{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Verify imports\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    import sys  \n",
    "    !{sys.executable} -m pip install matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\"\"\"\n",
    "Potential datasets:\n",
    "https://www.openml.org/d/42738\n",
    "https://www.openml.org/d/251\n",
    "https://www.openml.org/d/1000\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from sklearn import tree\n",
    "except:\n",
    "    import sys  \n",
    "    !{sys.executable} -m pip install sklearn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import pandas\n",
    "except:\n",
    "    import sys  \n",
    "    !{sys.executable} -m pip install pandas\n",
    "\n",
    "import time\n",
    "\n",
    "#import warnings\n",
    "\n",
    "#allow plots to appear within the notebook:\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All imports are good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Get the data\n",
    "dataset1 = load_breast_cancer()\n",
    "\n",
    "dataset_name = 'breast_cancer'\n",
    "#Failed OpenML sources:\n",
    "#'BNG(breast-w)' #insufficient source information\n",
    "#'hypothyroid' #errors\n",
    "#'open_payments' #errors\n",
    "#dataset1 = fetch_openml(name=dataset_name, version='active') \n",
    "dataset1.data = preprocessing.normalize(dataset1.data)\n",
    "#dataset1.data = preprocessing.scale(dataset1.data)\n",
    "dataset1.target = preprocessing.LabelEncoder().fit_transform(dataset1.target)\n",
    "X_ds1 = dataset1.data #matrix\n",
    "y_ds1 = dataset1.target #vector\n",
    "X_Train_ds1, X_Test_ds1, y_Train_ds1, y_Test_ds1 = \\\n",
    "    train_test_split(X_ds1, y_ds1, test_size=0.2, random_state=0) \n",
    "\n",
    "#Other global variables:\n",
    "cv_ds1 = 0\n",
    "criterion_ds1 = ''\n",
    "current_dataset = \"Dataset (\"+dataset_name+\")\"\n",
    "is_debug = False\n",
    "\n",
    "print(\"Data gotten, and other global variables initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Functions\n",
    "\n",
    "def decisionTree(X_Train, y_Train, cv_max=100):\n",
    "    cross_val_sizes = range(2,(cv_max+1))\n",
    "    criteria = ['gini','entropy']\n",
    "    best_score = 0\n",
    "    min_score = 1.0\n",
    "    cv_ds = 0\n",
    "    criterion_ds = ''\n",
    "    \n",
    "    print(\"Exploring Decision Trees with no pruning...\")\n",
    "    start = time.time()\n",
    "    for criterion in criteria:\n",
    "    \n",
    "        scores = []\n",
    "        for i in cross_val_sizes:\n",
    "            #with warnings.catch_warnings():\n",
    "            #    warnings.filterwarnings('error','warn')\n",
    "            dtc = tree.DecisionTreeClassifier(random_state=0, criterion=criterion)\n",
    "            score = cross_val_score(dtc, X_Train, y_Train, cv=i).mean()\n",
    "            scores.append(score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                cv_ds = i\n",
    "                criterion_ds=criterion\n",
    "                print(\"cv=\" + str(i) + \", criterion=\"+criterion+\" : \" + str(score))\n",
    "            if score < min_score:\n",
    "                min_score = score\n",
    "\n",
    "        plt.plot(cross_val_sizes, scores, label=criterion)\n",
    "        plt.xlabel(\"Cross validation size\")\n",
    "        plt.ylabel(\"Cross validation score (Performance)\")\n",
    "    \n",
    "    plt.legend() \n",
    "    plt.show()   \n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Decision Trees \" + current_dataset + \" best score = \" + str(best_score) + \" at cv = \" \\\n",
    "          + str(cv_ds) + \"(criterion=\"+criterion_ds+\") in \"+ getTime(end - start))\n",
    "    \n",
    "    #with warnings.catch_warnings():\n",
    "    #    warnings.filterwarnings('error','warn')\n",
    "    dtc = tree.DecisionTreeClassifier(random_state=0, criterion=criterion_ds)\n",
    "    return cv_ds, criterion_ds, min_score, dtc\n",
    "\n",
    "def decisionTreePrePruning(X_Train, y_Train, cv_ds, criterion_ds):\n",
    "    max_depth_sizes = range(2,21)\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "    min_score = 1.0\n",
    "    max_depth_ds = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Exploring Decision Trees with pre-pruning...\")\n",
    "    for md in max_depth_sizes:\n",
    "        dtc = tree.DecisionTreeClassifier(random_state=0, max_depth=md)\n",
    "        score = cross_val_score(dtc, X_Train, y_Train, cv=cv_ds).mean()\n",
    "        scores.append(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            max_depth_ds = md\n",
    "            print(str(md) + \" : \" + str(score))\n",
    "        if score < min_score:\n",
    "            min_score = score\n",
    "            \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Decision Trees \" + current_dataset + \" with pre-pruning best score = \" \\\n",
    "        + str(best_score) + \" at max_depth = \" + str(max_depth_ds) + \" in \"+ getTime(end - start))\n",
    "    plt.plot(max_depth_sizes, scores)\n",
    "    plt.xlabel(\"Max depth size\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    dtc = tree.DecisionTreeClassifier(random_state=0, max_depth=max_depth_ds)\n",
    "    \n",
    "    return min_score, dtc\n",
    "\n",
    "def decisionTreePostPruning(X_Train, y_Train, cv_ds, criterion_ds):\n",
    "    ccp_alpha_sizes = range(0,11)\n",
    "    scores = []\n",
    "    best_score = 0\n",
    "    min_score = 1.0\n",
    "    ccp_alpha_ds = 0\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    print(\"Exploring Decision Trees with post-pruning...\")\n",
    "    for ccpa in ccp_alpha_sizes:\n",
    "        dtc = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccpa)\n",
    "        score = cross_val_score(dtc, X_Train, y_Train, cv=cv_ds).mean()\n",
    "        scores.append(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            ccp_alpha_ds = ccpa\n",
    "            print(str(ccpa) + \" : \" + str(score))\n",
    "        if score < min_score:\n",
    "            min_score = score\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(\"Decision Trees \" + current_dataset + \" with post-pruning best score = \" \\\n",
    "        + str(best_score) + \" at ccp_alpha = \" + str(ccp_alpha_ds) + \" in \"+ getTime(end - start))\n",
    "    plt.plot(ccp_alpha_sizes, scores)\n",
    "    plt.xlabel(\"CCP alpha size\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    dtc = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha_ds)\n",
    "    \n",
    "    return min_score, dtc\n",
    "\n",
    "def confusionMatrix(X_Train, X_Test, y_Train, y_Test, clf, normalize, is_debug=False):\n",
    "    #normalize options: {‘true’, ‘pred’, ‘all’}, default=None\n",
    "    #with warnings.catch_warnings():\n",
    "    #    warnings.filterwarnings('error','warn')\n",
    "    #    try:\n",
    "    clf.fit(X_Train, y_Train)\n",
    "    #    except Warning:\n",
    "    #        if is_debug: print(\"Caught warning where clf = \" + str(clf) + \" and normalize = \" + normalize)\n",
    "    plot_confusion_matrix(clf, X_Test, y_Test, normalize=normalize, cmap=plt.cm.Blues)  \n",
    "    plt.show() \n",
    "    \n",
    "def plot_learning_curve(estimator, X, y, cv_n_splits, min_score):\n",
    "    \n",
    "    train_sizes=np.linspace(.1, 1.0, 5)\n",
    "    ylim=((min_score - 0.1), 1.01)\n",
    "    _, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    axes[0].set_title(\"Learning Curves\")\n",
    "\n",
    "    axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=cv_n_splits, test_size=0.2, random_state=0)\n",
    "    n_jobs=-1\n",
    "    \n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def getTime(seconds):\n",
    "    if int(seconds / 60) == 0:\n",
    "        return str(int(seconds)) + \" second(s)\"\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    if int(minutes / 60) == 0:\n",
    "        return str(minutes) + \" minute(s) and \" + str(seconds) + \" second(s)\"\n",
    "    hours = int(minutes / 60)\n",
    "    minutes = int(minutes % 60)\n",
    "    return str(hours) + \" hour(s), \" + str(minutes) + \" minute(s), and \" + str(seconds) + \" second(s)\"\n",
    "\n",
    "print(\"Functions have been defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Explore Dataset 1\n",
    "print(current_dataset + \" target names:\")\n",
    "print(dataset1.target_names) \n",
    "print(current_dataset + \" targets:\")\n",
    "print(np.unique(dataset1.target))\n",
    "print(current_dataset + \" data shape:\")\n",
    "print(X_ds1.shape) \n",
    "print(\"rows: \" + str(X_ds1.shape[0]) + \"; columns: \" + str(X_ds1.shape[1]))\n",
    "print(current_dataset + \" description:\")\n",
    "print(dataset1.DESCR) \n",
    "print() \n",
    "\n",
    "#4.1 Decision Trees\n",
    "cv_ds1, criterion_ds1, min_score, clf = decisionTree(X_Train_ds1, y_Train_ds1)\n",
    "\n",
    "confusionMatrix(X_Train_ds1, X_Test_ds1, y_Train_ds1, y_Test_ds1, clf, 'true')\n",
    "plot_learning_curve(clf, X_ds1, y_ds1, cv_ds1, min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-freedom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
